# TruthfulQA Environment Configuration
# Copy this file to .env.local and fill in your API keys
# Usage: source .env.local

# Required: Gemini API key for judge metrics
export GEMINI_API_KEY="your_gemini_api_key_here"

# Optional: HuggingFace token for gated models (e.g., Llama)
export HF_TOKEN="your_huggingface_token_here"

# Optional: OpenAI API key (for legacy GPT-3 judge compatibility)
export OPENAI_API_KEY="your_openai_api_key_here"

# Optional: Custom cache directory for HuggingFace models
export HF_HOME="/workspace/hf_cache"

# Optional: vLLM settings
export VLLM_WORKER_MULTIPROC_METHOD="spawn"

# Optional: CUDA settings
export CUDA_VISIBLE_DEVICES="0"
